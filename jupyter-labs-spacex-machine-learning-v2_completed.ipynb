{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca67257",
   "metadata": {},
   "source": [
    "# SpaceX Falcon 9 – Predictive Analysis (Classification)\n",
    "\n",
    "Este notebook entrena **múltiples modelos de clasificación** para predecir el resultado de lanzamiento (éxito/fracaso) usando el dataset del Capstone de IBM.\n",
    "\n",
    "**Repositorio del proyecto:** https://github.com/martumaida09-a11y/Files-with-proyect-IBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead5ce38",
   "metadata": {},
   "source": [
    "## 1) Cargar datos\n",
    "\n",
    "Se intenta leer `dataset_part_2.csv` local. Si no existe, se descarga desde un repositorio público.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c4712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "local_path = \"dataset_part_2.csv\"\n",
    "if not os.path.exists(local_path):\n",
    "    url = \"https://raw.githubusercontent.com/chuksoo/IBM-Data-Science-Capstone-SpaceX/main/dataset_part_2.csv\"\n",
    "    print(f\"Descargando dataset desde: {url}\")\n",
    "    urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "df = pd.read_csv(local_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28792138",
   "metadata": {},
   "source": [
    "## 2) Selección de features + One-Hot Encoding\n",
    "\n",
    "- Variables numéricas: `FlightNumber`, `PayloadMass`, `Flights`, `Block`, `ReusedCount`\n",
    "- Variables binarias: `GridFins`, `Reused`, `Legs`\n",
    "- Variables categóricas: `Orbit`, `LaunchSite`, `LandingPad`, `Serial`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b28b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'FlightNumber','PayloadMass','Orbit','LaunchSite','Flights',\n",
    "    'GridFins','Reused','Legs','LandingPad','Block','ReusedCount','Serial'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['Class'].astype(int)\n",
    "\n",
    "X_encoded = pd.get_dummies(\n",
    "    X,\n",
    "    columns=['Orbit','LaunchSite','LandingPad','Serial'],\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "print(\"Shape X:\", X_encoded.shape)\n",
    "print(\"Shape y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355d119",
   "metadata": {},
   "source": [
    "## 3) Split train/test + escalado\n",
    "\n",
    "> Igual que en los labs: `test_size=0.2`, `random_state=2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da401b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=2\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train:\", X_train_s.shape, \" Test:\", X_test_s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9f141",
   "metadata": {},
   "source": [
    "## 4) Entrenar múltiples modelos + evaluación\n",
    "\n",
    "Se compara:\n",
    "- Logistic Regression\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- KNN\n",
    "\n",
    "Con una búsqueda de hiperparámetros simple (`GridSearchCV`, `cv=5`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a02e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_logreg = {'C':[0.01,0.1,1,10], 'penalty':['l2'], 'solver':['lbfgs']}\n",
    "param_svm = {'kernel':['linear','rbf'], 'C':[0.1,1,10], 'gamma':['scale','auto']}\n",
    "param_tree={'criterion':['gini','entropy'], 'max_depth':[2,4,6,8,None], 'min_samples_split':[2,3,4]}\n",
    "param_knn={'n_neighbors':[1,3,5,7,9], 'p':[1,2]}\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=5000), param_logreg, True),\n",
    "    \"SVM\": (SVC(), param_svm, True),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=2), param_tree, False),\n",
    "    \"KNN\": (KNeighborsClassifier(), param_knn, True),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "best = {}\n",
    "\n",
    "for name, (estimator, params, needs_scaling) in models.items():\n",
    "    Xtr = X_train_s if needs_scaling else X_train\n",
    "    Xte = X_test_s if needs_scaling else X_test\n",
    "\n",
    "    gs = GridSearchCV(estimator, params, cv=5, scoring=\"accuracy\")\n",
    "    gs.fit(Xtr, y_train)\n",
    "\n",
    "    pred = gs.predict(Xte)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average='binary', pos_label=1)\n",
    "    rows.append([name, gs.best_params_, acc, prec, rec, f1])\n",
    "\n",
    "    best[name] = gs.best_estimator_\n",
    "\n",
    "results = pd.DataFrame(rows, columns=[\"Modelo\",\"Mejores parámetros\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"])\n",
    "results.sort_values(\"Accuracy\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac8171",
   "metadata": {},
   "source": [
    "## 5) Mejor modelo + Matriz de confusión\n",
    "\n",
    "Se elige el modelo con mejor **Accuracy/F1** (si hay empate, se prioriza interpretabilidad).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos Logistic Regression si está entre los mejores (interpretabilidad)\n",
    "best_model_name = \"Logistic Regression\"\n",
    "best_model = best[best_model_name]\n",
    "\n",
    "pred = best_model.predict(X_test_s)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b09381",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "im = ax.imshow(cm)\n",
    "ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(['Pred 0','Pred 1']); ax.set_yticklabels(['True 0','True 1'])\n",
    "for (i,j), val in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(val), ha='center', va='center',\n",
    "            color='white' if val>cm.max()/2 else 'black', fontsize=14)\n",
    "ax.set_title('Confusion Matrix – Logistic Regression')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20553004",
   "metadata": {},
   "source": [
    "## 6) Conclusión\n",
    "\n",
    "- El modelo **Logistic Regression** logra buen desempeño y es interpretable.\n",
    "- Próximos pasos: incorporar variables externas (clima, viento), calibrar el umbral para reducir falsos positivos y evaluar validación temporal.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
